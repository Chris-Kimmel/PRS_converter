{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading the HDF5 file ###\n",
    "\n",
    "READPATH = \"/fs/project/PAS1405/General/Kimmel_Chris/061120_8079m6A_IVTcarrierRNA_ligation_polyA.tombo.per_read_stats\"\n",
    "\n",
    "with h5py.File(READPATH, 'r') as hdf5file:\n",
    "    block_stats = hdf5file['Statistic_Blocks']['Block_0']['block_stats'] \n",
    "    read_ids = hdf5file['Statistic_Blocks']['Block_0']['read_ids']\n",
    "    \n",
    "    bs_struct_array = np.asarray(block_stats)\n",
    "    riv_array = np.asarray(read_ids)\n",
    "\n",
    "bs_rec_array = np.rec.array(bs_struct_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28107436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bs_rec_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate some basic data and initialize the table ###\n",
    "\n",
    "pos_array = bs_rec_array['pos'] # make array from the nucleotide-position column\n",
    "rin_array = bs_rec_array['read_id'] # make array from the read-id-number column\n",
    "\n",
    "pos_set = set(pos_array)\n",
    "num_poss = len(pos_set)\n",
    "pos_tuple = sorted(tuple(pos_set))\n",
    "\n",
    "rin_set = set(rin_array)\n",
    "num_reads = len(rin_set)\n",
    "rin_tuple = sorted(tuple(rin_set))\n",
    "\n",
    "table = np.full((num_reads, num_poss), np.nan, np.dtype('f8'), order='C') # Interestingly, order='F' doesn't seem slower\n",
    "''' There is one row in table for every rin, and one column for every position.\n",
    "The rin corresponding to row i is rin_tuple(i). The position corresponding to position j is pos_tuple(j).\n",
    "We need to fill the table very quickly, so we need a fast way to look up the *row* corresponding\n",
    "to a given *rin*, and the *column* corresponding to a given *position*.\n",
    "That's what pos_to_col_index and rin_to_row_index are for.\n",
    "'''\n",
    "pos_to_col_index = {pos: index for index, pos in enumerate(pos_tuple)}\n",
    "rin_to_row_index = {read_id_number: index for index, read_id_number in enumerate(rin_tuple)}\n",
    "# Hopefully we won't need pos_to_col_index after we implement a faster way to fill in the table. NOPE we'll still need it.\n",
    "\n",
    "new_table = np.full((num_reads, num_poss), np.nan, np.dtype('f8'), order='C') # Interestingly, order='F' doesn't seem slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort bs_rec_array. Maybe try sorting primarily by 'pos'. That might help us fill the table faster below.\n",
    "# This step took me 20 seconds on a bs_rec_array with 28 million entries (Owens cluster, 1 node, 28 cores)\n",
    "bs_rec_array_sorted = bs_rec_array.copy()\n",
    "bs_rec_array_sorted.sort(order=['read_id','pos'], kind='mergesort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/20\n",
      "Progress: 1/20\n",
      "Progress: 2/20\n",
      "Progress: 3/20\n",
      "Progress: 4/20\n",
      "Progress: 5/20\n",
      "Progress: 6/20\n",
      "Progress: 7/20\n",
      "Progress: 8/20\n",
      "Progress: 9/20\n",
      "Progress: 10/20\n",
      "Progress: 11/20\n",
      "Progress: 12/20\n",
      "Progress: 13/20\n",
      "Progress: 14/20\n",
      "Progress: 15/20\n",
      "Progress: 16/20\n",
      "Progress: 17/20\n",
      "Progress: 18/20\n",
      "Progress: 19/20\n",
      "Progress: 20/20\n"
     ]
    }
   ],
   "source": [
    "### OLD METHOD ###\n",
    "\n",
    "# On a 28-core CPU in the Owens cluster this loop took a little over 3 minutes on a rec_array with 28 million entries:\n",
    "num_checkpoints = 20\n",
    "checkpoint_size = len(bs_rec_array_sorted)//num_checkpoints\n",
    "for i, (pos, stat, read_id_number) in enumerate(bs_rec_array_sorted):\n",
    "    # TODO: Assert that this table position is already empty?\n",
    "    row_index = rin_to_row_index[read_id_number]\n",
    "    col_index = pos_to_col_index[pos]\n",
    "    table[row_index, col_index] = stat\n",
    "    if i % checkpoint_size == 0:\n",
    "        print('Progress: {}/{}'.format(i//checkpoint_size, num_checkpoints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/5\n",
      "Progress: 1/5\n",
      "Progress: 2/5\n",
      "Progress: 3/5\n",
      "Progress: 4/5\n",
      "Progress: 5/5\n"
     ]
    }
   ],
   "source": [
    "### Pull out slices of bs_rec_array_sorted, each one corresponding to a read ###\n",
    "\n",
    "number_of_records = bs_rec_array_sorted.shape[0]\n",
    "\n",
    "indices_preceeding_discontinuities = np.where((np.diff(bs_rec_array_sorted['read_id']) != 0)\n",
    "                                      | (np.diff(bs_rec_array_sorted['pos']) != 1)\n",
    "                                     )[0]\n",
    "indices_following_discontinuities = indices_preceeding_discontinuities + 1\n",
    "slice_boundaries = np.concatenate(([0], indices_following_discontinuities, [number_of_records]))\n",
    "\n",
    "for i, (st, sp) in enumerate(zip(slice_boundaries, slice_boundaries[1:])):\n",
    "    rin = bs_rec_array_sorted['read_id'][st]\n",
    "    row_index = rin_to_row_index[rin]\n",
    "    \n",
    "    # The business of looking up which positions we need to start and stop the entries at deserves closer scrutiny\n",
    "    # The code currently assumes that given slices of bs_rec_array_sorted have positions that increment one at a time.\n",
    "    # Combine ( np.diff(bs_rec_array_sorted['pos']) != 1 ) with np.diff(bs_rec_array_sorted['read_id']).nonzero() using\n",
    "    # ... some kind of entry-wise AND.\n",
    "    assert st < sp\n",
    "    low_pos = bs_rec_array_sorted['pos'][st]\n",
    "    high_pos = bs_rec_array_sorted['pos'][sp-1] # -1 because we're accessing a value...\n",
    "    assert low_pos < high_pos\n",
    "    low_col_index = pos_to_col_index[low_pos]\n",
    "    high_col_index = pos_to_col_index[high_pos]\n",
    "    assert low_col_index < high_col_index\n",
    "    \n",
    "    new_table[row_index,low_col_index:(high_col_index+1)] = bs_rec_array_sorted['stat'][st:sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isclose(new_table,table,equal_nan=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(~np.isclose(new_table, table, equal_nan=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.where(~np.isclose(new_table, table, equal_nan=True))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3f08e010f511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "rin[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(indices_preceeding_discontinuities) >= set(indices_preceeding_rid_changes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 [python/3.6 ]",
   "language": "python",
   "name": "sys_python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
